{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import gym\n",
    "import gridworld\n",
    "from gym import wrappers, logger\n",
    "\n",
    "\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding and Exploring openAi Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------  Introduction  ------------------------------------------ \n",
      "possible actions : \n",
      "----------------\n",
      "Discrete(4)\n",
      "\n",
      " after doing action 1 we get : \n",
      "(array([[1, 1, 1, 1, 1, 1],\n",
      "       [1, 0, 0, 0, 3, 1],\n",
      "       [1, 0, 1, 0, 5, 1],\n",
      "       [1, 0, 0, 0, 2, 1],\n",
      "       [1, 1, 1, 1, 1, 1],\n",
      "       [1, 1, 1, 1, 1, 1]]), 0, False, {})\n",
      "----------------\n",
      "\n",
      " all possible states (statedic) :\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  0\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 2 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  1\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 2 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  2\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 2 5 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  3\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 2 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  4\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  5\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 2 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  6\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 2 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  7\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 2 1 0 5 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  8\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 2 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  9\n",
      "----------------\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 2 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  10\n",
      "----------------\n",
      "number of States :  11\n",
      "----------------\n",
      "---------------------------  Example of a state and its transitions  ------------------------------ \n",
      " state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "----------------\n",
      " \n",
      "\n",
      " its transitions : \n",
      "----------------\n",
      "\n",
      "\n",
      "##########\n",
      "action  0\n",
      "##########\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.8\n",
      "Reward :  0\n",
      "Done   :  False\n",
      "----------------\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.1\n",
      "Reward :  0\n",
      "Done   :  False\n",
      "----------------\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 2 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.1\n",
      "Reward :  0\n",
      "Done   :  False\n",
      "----------------\n",
      "##########\n",
      "action  1\n",
      "##########\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 2 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.8\n",
      "Reward :  -1\n",
      "Done   :  True\n",
      "----------------\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.1\n",
      "Reward :  0\n",
      "Done   :  False\n",
      "----------------\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 2 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.1\n",
      "Reward :  0\n",
      "Done   :  False\n",
      "----------------\n",
      "##########\n",
      "action  2\n",
      "##########\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.1\n",
      "Reward :  0\n",
      "Done   :  False\n",
      "----------------\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 2 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.1\n",
      "Reward :  -1\n",
      "Done   :  True\n",
      "----------------\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 2 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.8\n",
      "Reward :  0\n",
      "Done   :  False\n",
      "----------------\n",
      "##########\n",
      "action  3\n",
      "##########\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.1\n",
      "Reward :  0\n",
      "Done   :  False\n",
      "----------------\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 2 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.1\n",
      "Reward :  -1\n",
      "Done   :  True\n",
      "----------------\n",
      "next state : \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "Proba  :  0.8\n",
      "Reward :  0\n",
      "Done   :  False\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "### create the env\n",
    "env = gym.make(\"gridworld-v0\")\n",
    "\n",
    "# Init the seed  ( pseudo random )\n",
    "env.seed(0) \n",
    "\n",
    "print(\"-----------------------------------------------  Introduction  ------------------------------------------ \")\n",
    "\n",
    "# Print possible actions\n",
    "print(\"possible actions : \")  \n",
    "print(\"----------------\")\n",
    "print(env.action_space)\n",
    "\n",
    "# do action 1\n",
    "# return : Observation(next state) , reward , done ( Boolean : next state is terminal state so the game is \n",
    "#                                                              finished )\n",
    "print(\"\\n after doing action 1 we get : \")\n",
    "print(env.step(0))  \n",
    "print(\"----------------\")\n",
    "# Visualize the game ( the grid ) \n",
    "# env.render()  \n",
    "# Visualize the grid game in a console mode\n",
    "# env.render(mode=\"human\")\n",
    "\n",
    "# get statedic , MDP\n",
    "statedic, mdp = env.getMDP()\n",
    "# statedic : state -> encoded_number \n",
    "print(\"\\n all possible states (statedic) :\")\n",
    "print(\"----------------\")\n",
    "for state in statedic : \n",
    "    l = ast.literal_eval(state)\n",
    "    print(np.array(l))\n",
    "    print(\"==> \",statedic[state])\n",
    "    print(\"----------------\")\n",
    "print(\"number of States : \",len(statedic))\n",
    "print(\"----------------\")\n",
    "print(\"---------------------------  Example of a state and its transitions  ------------------------------ \")\n",
    "#         MDP : dict ( state => transitions from this state )\n",
    "# transitions : dict { action => [ (proba1 , next_state1 , reward1 , done) ,\n",
    "#                                  (proba2 , next_state2 , reward2 , done) ... ] }\n",
    "state, transitions = list(mdp.items())[0]  # state 0 for example  \n",
    "print(\" state : \" )\n",
    "print(np.array(ast.literal_eval(state)))\n",
    "print(\"----------------\")\n",
    "print(\" \\n\\n its transitions : \")\n",
    "print(\"----------------\\n\\n\")\n",
    "for a in transitions :\n",
    "    print(\"##########\")\n",
    "    print(\"action \",a)\n",
    "    print(\"##########\")\n",
    "    for nuplet in transitions[a] : \n",
    "        print(\"next state : \" )\n",
    "        print(np.array(ast.literal_eval(nuplet[1])))\n",
    "        print(\"Proba  : \" , nuplet[0] )\n",
    "        print(\"Reward : \" , nuplet[2] )\n",
    "        print(\"Done   : \" , nuplet[3] )\n",
    "        print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Terminal States are not on the MDP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing from MDP \n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 2 1]\n",
      " [1 0 1 0 5 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  5\n",
      "[[1 1 1 1 1 1]\n",
      " [1 0 0 0 3 1]\n",
      " [1 0 1 0 2 1]\n",
      " [1 0 0 0 0 1]\n",
      " [1 1 1 1 1 1]\n",
      " [1 1 1 1 1 1]]\n",
      "==>  1\n"
     ]
    }
   ],
   "source": [
    "missingMDP = set(statedic.keys()).difference(set(env.getMDP()[1].keys()))\n",
    "print(\"missing from MDP \")\n",
    "for s in missingMDP : \n",
    "    l = ast.literal_eval(s)\n",
    "    print(np.array(l))\n",
    "    print(\"==> \",statedic[s])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**they are encoded :**\n",
    "- **Win (Green) : 5**\n",
    "- **Defeat (Red) : 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid World Goal : \n",
    "\n",
    "The Agent **Blue** should harvest **Yellow** elements  and finish on a **Green** case .\n",
    "\n",
    "The agent should avoid **Pink** cases which penalizes , and **Red** ones which are terminal states  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding Mapping** : \n",
    "\n",
    "0 => Empty Case \n",
    "\n",
    "1 => Wall\n",
    "\n",
    "2 => Player ( Our Agent )\n",
    "\n",
    "3 => Green Case\n",
    "\n",
    "4 => Yellow Case\n",
    "\n",
    "5 => Red Case\n",
    "\n",
    "6 => Pink Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have different plans  **0 ===> 10** with several difficulty settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "statedic , MDP = env.getMDP()\n",
    "\n",
    "S = len(statedic)\n",
    "A = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_policy ( S , A , init=\"Deterministic\" ) : \n",
    "    \n",
    "    '''\n",
    "    S : number of states \n",
    "    A : number of actions\n",
    "    init : ( 'Deterministic' | 'Random' | 'Uniform' )\n",
    "    '''\n",
    "    if ( init == 'Uniform' ) :\n",
    "        return np.ones((S,A),dtype=np.float16) / A\n",
    "    \n",
    "    p = np.zeros((S,A),dtype=np.float16)\n",
    "    \n",
    "    if ( init == 'Deterministic' ) : \n",
    "        p[ list(range(9)) , np.random.choice ( 4 , size=9 ) ] = 1\n",
    "        return p \n",
    "        \n",
    "    # else random  rounded 1e-1  like [ 0.6 , 0.2 , 0.0 , 0.1 ]\n",
    "    for i in range (S) :\n",
    "        Sum = 0 \n",
    "        for j in range (A) :\n",
    "            if ( j < A-1 ) : \n",
    "                p[i][j] = round( np.random.rand() * ( 1-Sum ) , 1 )\n",
    "                Sum += p[i][j]\n",
    "                if ( Sum >= 1 ):\n",
    "                    break\n",
    "            else :\n",
    "                p[i][j] = (1-Sum)\n",
    "    return np.round(p,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "deter_policy =  gen_policy ( S , A )\n",
    "rand_policy  =  gen_policy ( S , A , 'Random' )\n",
    "uni_policy   =  gen_policy ( S , A , 'Uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deter_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0.2, 0.8],\n",
       "       [0.1, 0.6, 0. , 0.3],\n",
       "       [0.5, 0.1, 0.1, 0.3],\n",
       "       [0.5, 0.5, 0. , 0. ],\n",
       "       [0.8, 0.2, 0. , 0. ],\n",
       "       [0.6, 0.1, 0.2, 0.1],\n",
       "       [0.3, 0.3, 0.3, 0.1],\n",
       "       [0.8, 0.1, 0.1, 0. ],\n",
       "       [0.7, 0. , 0. , 0.3],\n",
       "       [0.3, 0.6, 0. , 0.1],\n",
       "       [0.4, 0.2, 0.3, 0.1]], dtype=float16)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25]], dtype=float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Policy_eval ( env , Policy , Eps=1e-5 , discount=0.99 , verbose =True ) :\n",
    "    \n",
    "    # init \n",
    "    statedic , MDP = env.getMDP()\n",
    "    V_prev = np.random.rand( env.nS )\n",
    "    actions = np.arange( env.nA )\n",
    "    \n",
    "    #for printing \n",
    "    n_iter_eval = 1\n",
    "    \n",
    "    # loop applying Bellman Operator untill convergence   \n",
    "    while(True) : \n",
    "        V_curr = np.zeros ( V_prev.shape ) \n",
    "        # for each state s_t\n",
    "        for s in MDP :\n",
    "            Sum_a = 0 \n",
    "            # action according to policy\n",
    "            for a in MDP[s] :\n",
    "                Pi_s_a = Policy[ statedic[s] ][a]\n",
    "                if ( Pi_s_a > 0 ) :\n",
    "                    # for each state s_t+1 \n",
    "                    Sum_snext = 0\n",
    "                    for proba, next_state, reward, done in MDP[s][a] :\n",
    "                        Sum_snext +=   (proba * ( reward + discount * V_prev[ statedic[next_state] ] ))\n",
    "                    \n",
    "                    Sum_a += Pi_s_a * Sum_snext\n",
    "                    \n",
    "            V_curr[ statedic[s] ] = Sum_a\n",
    "            \n",
    "        if ( np.linalg.norm( V_curr - V_prev ) < Eps ) :\n",
    "            if ( verbose == True ) : print(\"n_iter_eval for convergence : \",n_iter_eval)\n",
    "            break \n",
    "        \n",
    "        n_iter_eval += 1 \n",
    "        V_prev = V_curr\n",
    "\n",
    "    return V_curr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter_eval for convergence :  108\n"
     ]
    }
   ],
   "source": [
    "V = Policy_eval ( env , deter_policy , Eps=1e-5 , discount=0.99 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.93690001,  0.        , -0.44592837, -0.50296922, -0.32583501,\n",
       "        0.        , -0.27761546, -0.2574881 , -0.1225327 ,  0.        ,\n",
       "        0.        ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Since state 1 and 5 are terminal states there will be no policies for them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Policy_iteration ( env , Eps=1e-5 , discount=0.99 , init='Uniform' , verbose = False  ) : \n",
    "    \n",
    "    \n",
    "    # init \n",
    "    statedic , MDP = env.getMDP()\n",
    "    P_prev = gen_policy ( env.nS , env.nA , init )\n",
    "    actions = np.arange( env.nA )\n",
    "    \n",
    "    n_iter_policy = 1\n",
    "    while ( True ): \n",
    "        # Policy Evaluation \n",
    "        V = Policy_eval ( env , P_prev , Eps=Eps , discount=discount , verbose=False )\n",
    "        \n",
    "        # Improvement\n",
    "        P_curr = np.zeros ( P_prev.shape )\n",
    "        for s in MDP :\n",
    "            # lookahead\n",
    "            acts = np.zeros( env.nA ) \n",
    "            for a in MDP[s] :\n",
    "                Sum_snext = 0\n",
    "                for proba, next_state, reward, done in MDP[s][a] :\n",
    "                    Sum_snext +=   (proba * ( reward + discount * V[ statedic[next_state] ] ))\n",
    "                acts[a] = Sum_snext\n",
    "            # select the argmax         \n",
    "            P_curr[ statedic[s] ][ acts.argmax() ] = 1.0\n",
    "            \n",
    "        if ( np.array_equal(P_prev,P_curr) ) :\n",
    "            if ( verbose ) : print(\"n_iter_policy for convergence : \",n_iter_policy)\n",
    "            break\n",
    "            \n",
    "        n_iter_policy += 1 \n",
    "        \n",
    "        # Printing\n",
    "        if ( verbose ) : \n",
    "            print(\"--------------------\")\n",
    "            print(P_prev)\n",
    "            print(P_curr)\n",
    "            print(\"--------------------\")\n",
    "        P_prev = P_curr\n",
    "\n",
    "    return P_curr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "P1 = Policy_iteration ( env, Eps=1e-5 , discount=0.99   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Value_iteration ( env , Eps=1e-5 , discount=0.99 , init='Uniform' , verbose = True  ) :\n",
    "    \n",
    "    # init \n",
    "    statedic , MDP = env.getMDP()\n",
    "    V_prev = np.random.rand( env.nS )\n",
    "    actions = np.arange( env.nA )\n",
    "    \n",
    "    P = np.zeros  ( (env.nS,env.nA) )\n",
    "    \n",
    "    n_iter = 1 \n",
    "    while ( True ) :\n",
    "        \n",
    "        # value iteration \n",
    "        V_curr = np.zeros ( V_prev.shape ) \n",
    "        # for each state s_t\n",
    "        for s in MDP :\n",
    "            # lookahead\n",
    "            acts = np.zeros( env.nA ) \n",
    "            for a in MDP[s] :\n",
    "                Sum_snext = 0\n",
    "                for proba, next_state, reward, done in MDP[s][a] :\n",
    "                    Sum_snext +=   (proba * ( reward + discount * V_prev[ statedic[next_state] ] ))\n",
    "                acts[a] = Sum_snext\n",
    "                    \n",
    "            V_curr[ statedic[s] ] = acts.max()\n",
    "            \n",
    "        if ( np.linalg.norm( V_curr - V_prev ) < Eps ) :\n",
    "            if ( verbose == True ) : print(\"n_iter_value_iteration for convergence : \",n_iter)\n",
    "            break\n",
    "            \n",
    "        n_iter += 1\n",
    "        V_prev = V_curr\n",
    "            \n",
    "    V  = V_curr\n",
    "    # create a policy\n",
    "    for s in MDP :\n",
    "        # lookahead\n",
    "        acts = np.zeros( env.nA ) \n",
    "        for a in MDP[s] :\n",
    "            Sum_snext = 0\n",
    "            for proba, next_state, reward, done in MDP[s][a] :\n",
    "                Sum_snext +=   (proba * ( reward + discount * V[ statedic[next_state] ] ))\n",
    "            acts[a] = Sum_snext\n",
    "        # select the argmax         \n",
    "        P[ statedic[s] ][ acts.argmax() ] = 1.0\n",
    "    \n",
    "    return P "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iter_value_iteration for convergence :  85\n"
     ]
    }
   ],
   "source": [
    "P2 = Value_iteration ( env, Eps=1e-5 , discount=0.99   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(object):\n",
    "    \"\"\"The world's simplest agent!\"\"\"\n",
    "\n",
    "    def __init__(self, action_space):\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def act(self, observation, reward, done):\n",
    "        return self.action_space.sample()\n",
    "    \n",
    "class DeterministicPolicy_Agent(object):\n",
    "    \"\"\"An agent using a deterministic policy generated by Policy Iteration Algorithm !\"\"\"\n",
    "    \n",
    "    def __init__(self, env, Method=\"Policy_iteration\", init=\"Uniform\", discount=0.99 ):\n",
    "        \n",
    "        self.action_space = env.action_space\n",
    "        self.policy       = globals()[Method]( env , Eps=1e-5 , discount=discount , init=init , verbose = False  )\n",
    "                        \n",
    "    def act(self, observation , reward , done ):\n",
    "        return self.policy[observation].argmax()\n",
    "    \n",
    "    \n",
    "class Epsilon_Policy_Agent(object):\n",
    "    \"\"\"An agent using a deterministic policy generated by Policy Iteration Algorithm !\"\"\"\n",
    "    def __init__(self, env, eps = 0.9, Method=\"Policy_iteration\", init=\"Uniform\", discount=0.99):\n",
    "        self.action_space = env.action_space\n",
    "        self.policy       = globals()[Method]( env , Eps=1e-5 , discount=discount , init=init , verbose = False  )\n",
    "        self.eps          = eps\n",
    "    \n",
    "    def act(self, observation , reward , done ):\n",
    "        if ( np.random.rand() <= self.eps ) :\n",
    "            return self.policy[observation].argmax()\n",
    "        else :\n",
    "            return self.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 0 rsum=0.94, 61 actions\n",
      "Episode : 1 rsum=0.951, 50 actions\n",
      "Episode : 2 rsum=0.959, 42 actions\n",
      "Episode : 3 rsum=0.951, 50 actions\n",
      "Episode : 4 rsum=0.953, 48 actions\n",
      "Episode : 5 rsum=0.938, 63 actions\n",
      "Episode : 6 rsum=0.95, 51 actions\n",
      "Episode : 7 rsum=0.953, 48 actions\n",
      "Episode : 8 rsum=0.946, 55 actions\n",
      "Episode : 9 rsum=0.962, 39 actions\n",
      "Episode : 10 rsum=0.955, 46 actions\n",
      "Episode : 11 rsum=0.96, 41 actions\n",
      "Episode : 12 rsum=0.952, 49 actions\n",
      "Episode : 13 rsum=0.956, 45 actions\n",
      "Episode : 14 rsum=0.953, 48 actions\n",
      "Episode : 15 rsum=0.959, 42 actions\n",
      "Episode : 16 rsum=0.943, 58 actions\n",
      "Episode : 17 rsum=0.956, 45 actions\n",
      "Episode : 18 rsum=0.959, 42 actions\n",
      "Episode : 19 rsum=0.95, 51 actions\n",
      "Episode : 20 rsum=0.957, 44 actions\n",
      "Episode : 21 rsum=0.958, 43 actions\n",
      "Episode : 22 rsum=0.949, 52 actions\n",
      "Episode : 23 rsum=0.953, 48 actions\n",
      "Episode : 24 rsum=0.946, 55 actions\n",
      "Episode : 25 rsum=0.9349999999999999, 66 actions\n",
      "Episode : 26 rsum=0.955, 46 actions\n",
      "Episode : 27 rsum=0.954, 47 actions\n",
      "Episode : 28 rsum=0.957, 44 actions\n",
      "Episode : 29 rsum=0.952, 49 actions\n",
      "Episode : 30 rsum=0.96, 41 actions\n",
      "Episode : 31 rsum=0.951, 50 actions\n",
      "Episode : 32 rsum=0.942, 59 actions\n",
      "Episode : 33 rsum=0.948, 53 actions\n",
      "Episode : 34 rsum=0.95, 51 actions\n",
      "Episode : 35 rsum=0.957, 44 actions\n",
      "Episode : 36 rsum=0.954, 47 actions\n",
      "Episode : 37 rsum=0.952, 49 actions\n",
      "Episode : 38 rsum=0.952, 49 actions\n",
      "Episode : 39 rsum=0.955, 46 actions\n",
      "Episode : 40 rsum=0.949, 52 actions\n",
      "Episode : 41 rsum=0.955, 46 actions\n",
      "Episode : 42 rsum=0.956, 45 actions\n",
      "Episode : 43 rsum=0.944, 57 actions\n",
      "Episode : 44 rsum=0.955, 46 actions\n",
      "Episode : 45 rsum=0.963, 38 actions\n",
      "Episode : 46 rsum=0.944, 57 actions\n",
      "Episode : 47 rsum=0.949, 52 actions\n",
      "Episode : 48 rsum=0.96, 41 actions\n",
      "Episode : 49 rsum=0.956, 45 actions\n",
      "Episode : 50 rsum=0.959, 42 actions\n",
      "Episode : 51 rsum=0.955, 46 actions\n",
      "Episode : 52 rsum=0.956, 45 actions\n",
      "Episode : 53 rsum=0.957, 44 actions\n",
      "Episode : 54 rsum=0.953, 48 actions\n",
      "Episode : 55 rsum=0.957, 44 actions\n",
      "Episode : 56 rsum=0.955, 46 actions\n",
      "Episode : 57 rsum=0.953, 48 actions\n",
      "Episode : 58 rsum=0.951, 50 actions\n",
      "Episode : 59 rsum=0.944, 57 actions\n",
      "Episode : 60 rsum=0.959, 42 actions\n",
      "Episode : 61 rsum=0.957, 44 actions\n",
      "Episode : 62 rsum=0.955, 46 actions\n",
      "Episode : 63 rsum=0.954, 47 actions\n",
      "Episode : 64 rsum=0.951, 50 actions\n",
      "Episode : 65 rsum=0.946, 55 actions\n",
      "Episode : 66 rsum=0.952, 49 actions\n",
      "Episode : 67 rsum=0.946, 55 actions\n",
      "Episode : 68 rsum=0.953, 48 actions\n",
      "Episode : 69 rsum=0.95, 51 actions\n",
      "Episode : 70 rsum=0.949, 52 actions\n",
      "Episode : 71 rsum=0.956, 45 actions\n",
      "Episode : 72 rsum=0.957, 44 actions\n",
      "Episode : 73 rsum=0.957, 44 actions\n",
      "Episode : 74 rsum=0.947, 54 actions\n",
      "Episode : 75 rsum=0.948, 53 actions\n",
      "Episode : 76 rsum=0.952, 49 actions\n",
      "Episode : 77 rsum=0.957, 44 actions\n",
      "Episode : 78 rsum=0.945, 56 actions\n",
      "Episode : 79 rsum=0.956, 45 actions\n",
      "Episode : 80 rsum=0.954, 47 actions\n",
      "Episode : 81 rsum=0.951, 50 actions\n",
      "Episode : 82 rsum=0.954, 47 actions\n",
      "Episode : 83 rsum=0.95, 51 actions\n",
      "Episode : 84 rsum=0.954, 47 actions\n",
      "Episode : 85 rsum=0.95, 51 actions\n",
      "Episode : 86 rsum=0.955, 46 actions\n",
      "Episode : 87 rsum=0.96, 41 actions\n",
      "Episode : 88 rsum=0.958, 43 actions\n",
      "Episode : 89 rsum=0.949, 52 actions\n",
      "Episode : 90 rsum=0.956, 45 actions\n",
      "Episode : 91 rsum=0.955, 46 actions\n",
      "Episode : 92 rsum=0.955, 46 actions\n",
      "Episode : 93 rsum=0.952, 49 actions\n",
      "Episode : 94 rsum=0.947, 54 actions\n",
      "Episode : 95 rsum=0.948, 53 actions\n",
      "Episode : 96 rsum=0.957, 44 actions\n",
      "Episode : 97 rsum=0.952, 49 actions\n",
      "Episode : 98 rsum=0.946, 55 actions\n",
      "Episode : 99 rsum=0.953, 48 actions\n",
      "Episode : 100 rsum=0.946, 55 actions\n",
      "Episode : 101 rsum=-1.001, 2 actions\n",
      "Episode : 102 rsum=0.951, 50 actions\n",
      "Episode : 103 rsum=0.956, 45 actions\n",
      "Episode : 104 rsum=0.945, 56 actions\n",
      "Episode : 105 rsum=0.947, 54 actions\n",
      "Episode : 106 rsum=0.957, 44 actions\n",
      "Episode : 107 rsum=0.954, 47 actions\n",
      "Episode : 108 rsum=0.952, 49 actions\n",
      "Episode : 109 rsum=0.949, 52 actions\n",
      "Episode : 110 rsum=0.957, 44 actions\n",
      "Episode : 111 rsum=0.963, 38 actions\n",
      "Episode : 112 rsum=-1, 1 actions\n",
      "Episode : 113 rsum=0.965, 36 actions\n",
      "Episode : 114 rsum=0.964, 37 actions\n",
      "Episode : 115 rsum=0.958, 43 actions\n",
      "Episode : 116 rsum=0.955, 46 actions\n",
      "Episode : 117 rsum=0.953, 48 actions\n",
      "Episode : 118 rsum=0.956, 45 actions\n",
      "Episode : 119 rsum=0.953, 48 actions\n",
      "Episode : 120 rsum=0.951, 50 actions\n",
      "Episode : 121 rsum=0.951, 50 actions\n",
      "Episode : 122 rsum=0.949, 52 actions\n",
      "Episode : 123 rsum=0.953, 48 actions\n",
      "Episode : 124 rsum=0.956, 45 actions\n",
      "Episode : 125 rsum=0.958, 43 actions\n",
      "Episode : 126 rsum=0.952, 49 actions\n",
      "Episode : 127 rsum=0.954, 47 actions\n",
      "Episode : 128 rsum=0.948, 53 actions\n",
      "Episode : 129 rsum=0.939, 62 actions\n",
      "Episode : 130 rsum=0.945, 56 actions\n",
      "Episode : 131 rsum=0.947, 54 actions\n",
      "Episode : 132 rsum=0.943, 58 actions\n",
      "Episode : 133 rsum=0.956, 45 actions\n",
      "Episode : 134 rsum=0.943, 58 actions\n",
      "Episode : 135 rsum=0.956, 45 actions\n",
      "Episode : 136 rsum=0.952, 49 actions\n",
      "Episode : 137 rsum=0.957, 44 actions\n",
      "Episode : 138 rsum=0.951, 50 actions\n",
      "Episode : 139 rsum=0.956, 45 actions\n",
      "Episode : 140 rsum=0.951, 50 actions\n",
      "Episode : 141 rsum=0.952, 49 actions\n",
      "Episode : 142 rsum=0.951, 50 actions\n",
      "Episode : 143 rsum=0.956, 45 actions\n",
      "Episode : 144 rsum=0.95, 51 actions\n",
      "Episode : 145 rsum=0.953, 48 actions\n",
      "Episode : 146 rsum=0.94, 61 actions\n",
      "Episode : 147 rsum=0.944, 57 actions\n",
      "Episode : 148 rsum=0.94, 61 actions\n",
      "Episode : 149 rsum=0.952, 49 actions\n",
      "Episode : 150 rsum=0.951, 50 actions\n",
      "Episode : 151 rsum=0.953, 48 actions\n",
      "Episode : 152 rsum=0.962, 39 actions\n",
      "Episode : 153 rsum=0.953, 48 actions\n",
      "Episode : 154 rsum=0.953, 48 actions\n",
      "Episode : 155 rsum=0.952, 49 actions\n",
      "Episode : 156 rsum=0.949, 52 actions\n",
      "Episode : 157 rsum=0.96, 41 actions\n",
      "Episode : 158 rsum=0.944, 57 actions\n",
      "Episode : 159 rsum=0.947, 54 actions\n",
      "Episode : 160 rsum=0.956, 45 actions\n",
      "Episode : 161 rsum=0.952, 49 actions\n",
      "Episode : 162 rsum=0.96, 41 actions\n",
      "Episode : 163 rsum=0.953, 48 actions\n",
      "Episode : 164 rsum=0.954, 47 actions\n",
      "Episode : 165 rsum=0.951, 50 actions\n",
      "Episode : 166 rsum=0.951, 50 actions\n",
      "Episode : 167 rsum=0.948, 53 actions\n",
      "Episode : 168 rsum=0.952, 49 actions\n",
      "Episode : 169 rsum=0.953, 48 actions\n",
      "Episode : 170 rsum=0.955, 46 actions\n",
      "Episode : 171 rsum=0.952, 49 actions\n",
      "Episode : 172 rsum=0.958, 43 actions\n",
      "Episode : 173 rsum=0.949, 52 actions\n",
      "Episode : 174 rsum=0.948, 53 actions\n",
      "Episode : 175 rsum=0.954, 47 actions\n",
      "Episode : 176 rsum=0.953, 48 actions\n",
      "Episode : 177 rsum=0.952, 49 actions\n",
      "Episode : 178 rsum=0.954, 47 actions\n",
      "Episode : 179 rsum=0.951, 50 actions\n",
      "Episode : 180 rsum=0.951, 50 actions\n",
      "Episode : 181 rsum=0.95, 51 actions\n",
      "Episode : 182 rsum=0.956, 45 actions\n",
      "Episode : 183 rsum=0.948, 53 actions\n",
      "Episode : 184 rsum=0.956, 45 actions\n",
      "Episode : 185 rsum=0.951, 50 actions\n",
      "Episode : 186 rsum=0.949, 52 actions\n",
      "Episode : 187 rsum=0.948, 53 actions\n",
      "Episode : 188 rsum=0.957, 44 actions\n",
      "Episode : 189 rsum=0.952, 49 actions\n",
      "Episode : 190 rsum=0.96, 41 actions\n",
      "Episode : 191 rsum=0.955, 46 actions\n",
      "Episode : 192 rsum=0.948, 53 actions\n",
      "Episode : 193 rsum=0.958, 43 actions\n",
      "Episode : 194 rsum=0.951, 50 actions\n",
      "Episode : 195 rsum=0.959, 42 actions\n",
      "Episode : 196 rsum=0.954, 47 actions\n",
      "Episode : 197 rsum=0.954, 47 actions\n",
      "Episode : 198 rsum=0.957, 44 actions\n",
      "Episode : 199 rsum=-1, 1 actions\n",
      "Episode : 200 rsum=0.952, 49 actions\n",
      "Episode : 201 rsum=0.949, 52 actions\n",
      "Episode : 202 rsum=0.95, 51 actions\n",
      "Episode : 203 rsum=0.959, 42 actions\n",
      "Episode : 204 rsum=0.953, 48 actions\n",
      "Episode : 205 rsum=0.954, 47 actions\n",
      "Episode : 206 rsum=0.95, 51 actions\n",
      "Episode : 207 rsum=0.954, 47 actions\n",
      "Episode : 208 rsum=0.949, 52 actions\n",
      "Episode : 209 rsum=0.956, 45 actions\n",
      "Episode : 210 rsum=0.952, 49 actions\n",
      "Episode : 211 rsum=0.944, 57 actions\n",
      "Episode : 212 rsum=0.946, 55 actions\n",
      "Episode : 213 rsum=0.952, 49 actions\n",
      "Episode : 214 rsum=0.958, 43 actions\n",
      "Episode : 215 rsum=0.958, 43 actions\n",
      "Episode : 216 rsum=0.946, 55 actions\n",
      "Episode : 217 rsum=0.961, 40 actions\n",
      "Episode : 218 rsum=0.942, 59 actions\n",
      "Episode : 219 rsum=0.953, 48 actions\n",
      "Episode : 220 rsum=0.957, 44 actions\n",
      "Episode : 221 rsum=0.95, 51 actions\n",
      "Episode : 222 rsum=0.956, 45 actions\n",
      "Episode : 223 rsum=0.96, 41 actions\n",
      "Episode : 224 rsum=0.957, 44 actions\n",
      "Episode : 225 rsum=0.955, 46 actions\n",
      "Episode : 226 rsum=0.953, 48 actions\n",
      "Episode : 227 rsum=0.948, 53 actions\n",
      "Episode : 228 rsum=0.963, 38 actions\n",
      "Episode : 229 rsum=0.949, 52 actions\n",
      "Episode : 230 rsum=0.947, 54 actions\n",
      "Episode : 231 rsum=0.951, 50 actions\n",
      "Episode : 232 rsum=-1.001, 2 actions\n",
      "Episode : 233 rsum=0.957, 44 actions\n",
      "Episode : 234 rsum=0.9349999999999999, 66 actions\n",
      "Episode : 235 rsum=0.95, 51 actions\n",
      "Episode : 236 rsum=0.95, 51 actions\n",
      "Episode : 237 rsum=0.953, 48 actions\n",
      "Episode : 238 rsum=0.96, 41 actions\n",
      "Episode : 239 rsum=0.954, 47 actions\n",
      "Episode : 240 rsum=0.953, 48 actions\n",
      "Episode : 241 rsum=0.954, 47 actions\n",
      "Episode : 242 rsum=0.962, 39 actions\n",
      "Episode : 243 rsum=0.959, 42 actions\n",
      "Episode : 244 rsum=0.945, 56 actions\n",
      "Episode : 245 rsum=0.947, 54 actions\n",
      "Episode : 246 rsum=0.947, 54 actions\n",
      "Episode : 247 rsum=-1, 1 actions\n",
      "Episode : 248 rsum=0.939, 62 actions\n",
      "Episode : 249 rsum=0.948, 53 actions\n",
      "Episode : 250 rsum=0.954, 47 actions\n",
      "Episode : 251 rsum=0.959, 42 actions\n",
      "Episode : 252 rsum=0.961, 40 actions\n",
      "Episode : 253 rsum=0.953, 48 actions\n",
      "Episode : 254 rsum=0.951, 50 actions\n",
      "Episode : 255 rsum=0.955, 46 actions\n",
      "Episode : 256 rsum=0.96, 41 actions\n",
      "Episode : 257 rsum=0.955, 46 actions\n",
      "Episode : 258 rsum=0.954, 47 actions\n",
      "Episode : 259 rsum=0.958, 43 actions\n",
      "Episode : 260 rsum=0.955, 46 actions\n",
      "Episode : 261 rsum=0.954, 47 actions\n",
      "Episode : 262 rsum=0.95, 51 actions\n",
      "Episode : 263 rsum=0.955, 46 actions\n",
      "Episode : 264 rsum=0.953, 48 actions\n",
      "Episode : 265 rsum=0.957, 44 actions\n",
      "Episode : 266 rsum=0.955, 46 actions\n",
      "Episode : 267 rsum=0.945, 56 actions\n",
      "Episode : 268 rsum=0.947, 54 actions\n",
      "Episode : 269 rsum=0.956, 45 actions\n",
      "Episode : 270 rsum=0.952, 49 actions\n",
      "Episode : 271 rsum=0.961, 40 actions\n",
      "Episode : 272 rsum=0.955, 46 actions\n",
      "Episode : 273 rsum=0.953, 48 actions\n",
      "Episode : 274 rsum=0.939, 62 actions\n",
      "Episode : 275 rsum=0.949, 52 actions\n",
      "Episode : 276 rsum=0.958, 43 actions\n",
      "Episode : 277 rsum=0.959, 42 actions\n",
      "Episode : 278 rsum=0.947, 54 actions\n",
      "Episode : 279 rsum=0.952, 49 actions\n",
      "Episode : 280 rsum=0.957, 44 actions\n",
      "Episode : 281 rsum=0.956, 45 actions\n",
      "Episode : 282 rsum=0.953, 48 actions\n",
      "Episode : 283 rsum=0.951, 50 actions\n",
      "Episode : 284 rsum=0.954, 47 actions\n",
      "Episode : 285 rsum=0.955, 46 actions\n",
      "Episode : 286 rsum=0.954, 47 actions\n",
      "Episode : 287 rsum=0.946, 55 actions\n",
      "Episode : 288 rsum=0.962, 39 actions\n",
      "Episode : 289 rsum=0.954, 47 actions\n",
      "Episode : 290 rsum=0.954, 47 actions\n",
      "Episode : 291 rsum=0.953, 48 actions\n",
      "Episode : 292 rsum=0.951, 50 actions\n",
      "Episode : 293 rsum=0.957, 44 actions\n",
      "Episode : 294 rsum=0.949, 52 actions\n",
      "Episode : 295 rsum=0.956, 45 actions\n",
      "Episode : 296 rsum=0.954, 47 actions\n",
      "Episode : 297 rsum=0.948, 53 actions\n",
      "Episode : 298 rsum=0.957, 44 actions\n",
      "Episode : 299 rsum=0.955, 46 actions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 300 rsum=0.96, 41 actions\n",
      "Episode : 301 rsum=0.957, 44 actions\n",
      "Episode : 302 rsum=-1, 1 actions\n",
      "Episode : 303 rsum=0.952, 49 actions\n",
      "Episode : 304 rsum=0.954, 47 actions\n",
      "Episode : 305 rsum=0.959, 42 actions\n",
      "Episode : 306 rsum=0.949, 52 actions\n",
      "Episode : 307 rsum=0.954, 47 actions\n",
      "Episode : 308 rsum=0.961, 40 actions\n",
      "Episode : 309 rsum=0.957, 44 actions\n",
      "Episode : 310 rsum=0.954, 47 actions\n",
      "Episode : 311 rsum=0.947, 54 actions\n",
      "Episode : 312 rsum=0.95, 51 actions\n",
      "Episode : 313 rsum=0.961, 40 actions\n",
      "Episode : 314 rsum=0.956, 45 actions\n",
      "Episode : 315 rsum=0.947, 54 actions\n",
      "Episode : 316 rsum=0.955, 46 actions\n",
      "Episode : 317 rsum=0.9359999999999999, 65 actions\n",
      "Episode : 318 rsum=0.952, 49 actions\n",
      "Episode : 319 rsum=0.949, 52 actions\n",
      "Episode : 320 rsum=0.956, 45 actions\n",
      "Episode : 321 rsum=0.959, 42 actions\n",
      "Episode : 322 rsum=0.952, 49 actions\n",
      "Episode : 323 rsum=0.955, 46 actions\n",
      "Episode : 324 rsum=0.96, 41 actions\n",
      "Episode : 325 rsum=0.944, 57 actions\n",
      "Episode : 326 rsum=0.95, 51 actions\n",
      "Episode : 327 rsum=0.946, 55 actions\n",
      "Episode : 328 rsum=0.957, 44 actions\n",
      "Episode : 329 rsum=0.953, 48 actions\n",
      "Episode : 330 rsum=0.955, 46 actions\n",
      "Episode : 331 rsum=0.951, 50 actions\n",
      "Episode : 332 rsum=0.956, 45 actions\n",
      "Episode : 333 rsum=0.948, 53 actions\n",
      "Episode : 334 rsum=0.958, 43 actions\n",
      "Episode : 335 rsum=0.957, 44 actions\n",
      "Episode : 336 rsum=0.946, 55 actions\n",
      "Episode : 337 rsum=0.959, 42 actions\n",
      "Episode : 338 rsum=0.951, 50 actions\n",
      "Episode : 339 rsum=0.953, 48 actions\n",
      "Episode : 340 rsum=0.946, 55 actions\n",
      "Episode : 341 rsum=0.952, 49 actions\n",
      "Episode : 342 rsum=0.953, 48 actions\n",
      "Episode : 343 rsum=0.953, 48 actions\n",
      "Episode : 344 rsum=0.957, 44 actions\n",
      "Episode : 345 rsum=0.955, 46 actions\n",
      "Episode : 346 rsum=0.952, 49 actions\n",
      "Episode : 347 rsum=0.954, 47 actions\n",
      "Episode : 348 rsum=0.961, 40 actions\n",
      "Episode : 349 rsum=0.958, 43 actions\n",
      "Episode : 350 rsum=0.954, 47 actions\n",
      "Episode : 351 rsum=0.951, 50 actions\n",
      "Episode : 352 rsum=0.958, 43 actions\n",
      "Episode : 353 rsum=0.947, 54 actions\n",
      "Episode : 354 rsum=0.949, 52 actions\n",
      "Episode : 355 rsum=0.951, 50 actions\n",
      "Episode : 356 rsum=0.953, 48 actions\n",
      "Episode : 357 rsum=0.959, 42 actions\n",
      "Episode : 358 rsum=0.954, 47 actions\n",
      "Episode : 359 rsum=0.949, 52 actions\n",
      "Episode : 360 rsum=0.943, 58 actions\n",
      "Episode : 361 rsum=0.951, 50 actions\n",
      "Episode : 362 rsum=0.95, 51 actions\n",
      "Episode : 363 rsum=0.953, 48 actions\n",
      "Episode : 364 rsum=0.953, 48 actions\n",
      "Episode : 365 rsum=0.953, 48 actions\n",
      "Episode : 366 rsum=0.953, 48 actions\n",
      "Episode : 367 rsum=0.956, 45 actions\n",
      "Episode : 368 rsum=0.952, 49 actions\n",
      "Episode : 369 rsum=0.941, 60 actions\n",
      "Episode : 370 rsum=0.947, 54 actions\n",
      "Episode : 371 rsum=0.948, 53 actions\n",
      "Episode : 372 rsum=0.948, 53 actions\n",
      "Episode : 373 rsum=0.955, 46 actions\n",
      "Episode : 374 rsum=0.956, 45 actions\n",
      "Episode : 375 rsum=0.951, 50 actions\n",
      "Episode : 376 rsum=0.956, 45 actions\n",
      "Episode : 377 rsum=0.954, 47 actions\n",
      "Episode : 378 rsum=0.961, 40 actions\n",
      "Episode : 379 rsum=0.954, 47 actions\n",
      "Episode : 380 rsum=0.955, 46 actions\n",
      "Episode : 381 rsum=0.961, 40 actions\n",
      "Episode : 382 rsum=0.961, 40 actions\n",
      "Episode : 383 rsum=0.952, 49 actions\n",
      "Episode : 384 rsum=0.944, 57 actions\n",
      "Episode : 385 rsum=0.949, 52 actions\n",
      "Episode : 386 rsum=0.958, 43 actions\n",
      "Episode : 387 rsum=0.955, 46 actions\n",
      "Episode : 388 rsum=0.95, 51 actions\n",
      "Episode : 389 rsum=0.954, 47 actions\n",
      "Episode : 390 rsum=0.957, 44 actions\n",
      "Episode : 391 rsum=0.96, 41 actions\n",
      "Episode : 392 rsum=0.952, 49 actions\n",
      "Episode : 393 rsum=0.95, 51 actions\n",
      "Episode : 394 rsum=0.954, 47 actions\n",
      "Episode : 395 rsum=0.939, 62 actions\n",
      "Episode : 396 rsum=0.957, 44 actions\n",
      "Episode : 397 rsum=0.96, 41 actions\n",
      "Episode : 398 rsum=0.956, 45 actions\n",
      "Episode : 399 rsum=0.954, 47 actions\n",
      "Episode : 400 rsum=0.959, 42 actions\n",
      "Episode : 401 rsum=0.957, 44 actions\n",
      "Episode : 402 rsum=0.957, 44 actions\n",
      "Episode : 403 rsum=0.955, 46 actions\n",
      "Episode : 404 rsum=0.953, 48 actions\n",
      "Episode : 405 rsum=0.953, 48 actions\n",
      "Episode : 406 rsum=0.954, 47 actions\n",
      "Episode : 407 rsum=0.947, 54 actions\n",
      "Episode : 408 rsum=0.955, 46 actions\n",
      "Episode : 409 rsum=0.956, 45 actions\n",
      "Episode : 410 rsum=0.954, 47 actions\n",
      "Episode : 411 rsum=0.945, 56 actions\n",
      "Episode : 412 rsum=0.948, 53 actions\n",
      "Episode : 413 rsum=0.954, 47 actions\n",
      "Episode : 414 rsum=-1, 1 actions\n",
      "Episode : 415 rsum=0.958, 43 actions\n",
      "Episode : 416 rsum=0.953, 48 actions\n",
      "Episode : 417 rsum=0.955, 46 actions\n",
      "Episode : 418 rsum=0.951, 50 actions\n",
      "Episode : 419 rsum=0.958, 43 actions\n",
      "Episode : 420 rsum=0.949, 52 actions\n",
      "Episode : 421 rsum=0.958, 43 actions\n",
      "Episode : 422 rsum=0.95, 51 actions\n",
      "Episode : 423 rsum=0.954, 47 actions\n",
      "Episode : 424 rsum=0.952, 49 actions\n",
      "Episode : 425 rsum=0.944, 57 actions\n",
      "Episode : 426 rsum=0.957, 44 actions\n",
      "Episode : 427 rsum=0.952, 49 actions\n",
      "Episode : 428 rsum=0.959, 42 actions\n",
      "Episode : 429 rsum=0.952, 49 actions\n",
      "Episode : 430 rsum=0.954, 47 actions\n",
      "Episode : 431 rsum=0.952, 49 actions\n",
      "Episode : 432 rsum=0.961, 40 actions\n",
      "Episode : 433 rsum=0.953, 48 actions\n",
      "Episode : 434 rsum=0.953, 48 actions\n",
      "Episode : 435 rsum=0.959, 42 actions\n",
      "Episode : 436 rsum=0.952, 49 actions\n",
      "Episode : 437 rsum=0.954, 47 actions\n",
      "Episode : 438 rsum=0.949, 52 actions\n",
      "Episode : 439 rsum=0.944, 57 actions\n",
      "Episode : 440 rsum=0.96, 41 actions\n",
      "Episode : 441 rsum=0.948, 53 actions\n",
      "Episode : 442 rsum=0.955, 46 actions\n",
      "Episode : 443 rsum=0.958, 43 actions\n",
      "Episode : 444 rsum=0.947, 54 actions\n",
      "Episode : 445 rsum=0.952, 49 actions\n",
      "Episode : 446 rsum=0.959, 42 actions\n",
      "Episode : 447 rsum=0.944, 57 actions\n",
      "Episode : 448 rsum=0.954, 47 actions\n",
      "Episode : 449 rsum=0.958, 43 actions\n",
      "Episode : 450 rsum=0.953, 48 actions\n",
      "Episode : 451 rsum=0.954, 47 actions\n",
      "Episode : 452 rsum=0.96, 41 actions\n",
      "Episode : 453 rsum=0.96, 41 actions\n",
      "Episode : 454 rsum=0.952, 49 actions\n",
      "Episode : 455 rsum=0.945, 56 actions\n",
      "Episode : 456 rsum=0.957, 44 actions\n",
      "Episode : 457 rsum=0.957, 44 actions\n",
      "Episode : 458 rsum=0.946, 55 actions\n",
      "Episode : 459 rsum=0.953, 48 actions\n",
      "Episode : 460 rsum=0.948, 53 actions\n",
      "Episode : 461 rsum=0.953, 48 actions\n",
      "Episode : 462 rsum=0.945, 56 actions\n",
      "Episode : 463 rsum=0.96, 41 actions\n",
      "Episode : 464 rsum=0.955, 46 actions\n",
      "Episode : 465 rsum=0.951, 50 actions\n",
      "Episode : 466 rsum=0.95, 51 actions\n",
      "Episode : 467 rsum=0.953, 48 actions\n",
      "Episode : 468 rsum=0.961, 40 actions\n",
      "Episode : 469 rsum=0.948, 53 actions\n",
      "Episode : 470 rsum=0.959, 42 actions\n",
      "Episode : 471 rsum=0.949, 52 actions\n",
      "Episode : 472 rsum=0.956, 45 actions\n",
      "Episode : 473 rsum=0.957, 44 actions\n",
      "Episode : 474 rsum=0.948, 53 actions\n",
      "Episode : 475 rsum=0.949, 52 actions\n",
      "Episode : 476 rsum=-1.001, 2 actions\n",
      "Episode : 477 rsum=0.948, 53 actions\n",
      "Episode : 478 rsum=0.963, 38 actions\n",
      "Episode : 479 rsum=0.961, 40 actions\n",
      "Episode : 480 rsum=0.959, 42 actions\n",
      "Episode : 481 rsum=0.954, 47 actions\n",
      "Episode : 482 rsum=0.95, 51 actions\n",
      "Episode : 483 rsum=0.956, 45 actions\n",
      "Episode : 484 rsum=0.956, 45 actions\n",
      "Episode : 485 rsum=0.947, 54 actions\n",
      "Episode : 486 rsum=0.954, 47 actions\n",
      "Episode : 487 rsum=0.958, 43 actions\n",
      "Episode : 488 rsum=0.953, 48 actions\n",
      "Episode : 489 rsum=0.951, 50 actions\n",
      "Episode : 490 rsum=0.949, 52 actions\n",
      "Episode : 491 rsum=0.956, 45 actions\n",
      "Episode : 492 rsum=0.952, 49 actions\n",
      "Episode : 493 rsum=0.95, 51 actions\n",
      "Episode : 494 rsum=0.947, 54 actions\n",
      "Episode : 495 rsum=0.954, 47 actions\n",
      "Episode : 496 rsum=0.954, 47 actions\n",
      "Episode : 497 rsum=0.96, 41 actions\n",
      "Episode : 498 rsum=0.955, 46 actions\n",
      "Episode : 499 rsum=0.944, 57 actions\n",
      "Episode : 500 rsum=0.95, 51 actions\n",
      "Episode : 501 rsum=0.951, 50 actions\n",
      "Episode : 502 rsum=0.954, 47 actions\n",
      "Episode : 503 rsum=0.943, 58 actions\n",
      "Episode : 504 rsum=0.958, 43 actions\n",
      "Episode : 505 rsum=0.955, 46 actions\n",
      "Episode : 506 rsum=0.959, 42 actions\n",
      "Episode : 507 rsum=0.951, 50 actions\n",
      "Episode : 508 rsum=0.952, 49 actions\n",
      "Episode : 509 rsum=0.959, 42 actions\n",
      "Episode : 510 rsum=0.954, 47 actions\n",
      "Episode : 511 rsum=0.948, 53 actions\n",
      "Episode : 512 rsum=0.962, 39 actions\n",
      "Episode : 513 rsum=0.95, 51 actions\n",
      "Episode : 514 rsum=0.957, 44 actions\n",
      "Episode : 515 rsum=0.945, 56 actions\n",
      "Episode : 516 rsum=0.954, 47 actions\n",
      "Episode : 517 rsum=0.952, 49 actions\n",
      "Episode : 518 rsum=0.952, 49 actions\n",
      "Episode : 519 rsum=0.949, 52 actions\n",
      "Episode : 520 rsum=0.951, 50 actions\n",
      "Episode : 521 rsum=0.942, 59 actions\n",
      "Episode : 522 rsum=0.955, 46 actions\n",
      "Episode : 523 rsum=0.959, 42 actions\n",
      "Episode : 524 rsum=0.942, 59 actions\n",
      "Episode : 525 rsum=0.95, 51 actions\n",
      "Episode : 526 rsum=0.943, 58 actions\n",
      "Episode : 527 rsum=0.957, 44 actions\n",
      "Episode : 528 rsum=0.954, 47 actions\n",
      "Episode : 529 rsum=0.949, 52 actions\n",
      "Episode : 530 rsum=0.955, 46 actions\n",
      "Episode : 531 rsum=0.95, 51 actions\n",
      "Episode : 532 rsum=0.952, 49 actions\n",
      "Episode : 533 rsum=0.956, 45 actions\n",
      "Episode : 534 rsum=0.95, 51 actions\n",
      "Episode : 535 rsum=0.953, 48 actions\n",
      "Episode : 536 rsum=0.949, 52 actions\n",
      "Episode : 537 rsum=0.95, 51 actions\n",
      "Episode : 538 rsum=0.951, 50 actions\n",
      "Episode : 539 rsum=0.945, 56 actions\n",
      "Episode : 540 rsum=0.957, 44 actions\n",
      "Episode : 541 rsum=0.95, 51 actions\n",
      "Episode : 542 rsum=0.941, 60 actions\n",
      "Episode : 543 rsum=0.959, 42 actions\n",
      "Episode : 544 rsum=0.955, 46 actions\n",
      "Episode : 545 rsum=0.957, 44 actions\n",
      "Episode : 546 rsum=0.957, 44 actions\n",
      "Episode : 547 rsum=0.951, 50 actions\n",
      "Episode : 548 rsum=0.951, 50 actions\n",
      "Episode : 549 rsum=0.955, 46 actions\n",
      "Episode : 550 rsum=0.951, 50 actions\n",
      "Episode : 551 rsum=0.955, 46 actions\n",
      "Episode : 552 rsum=0.955, 46 actions\n",
      "Episode : 553 rsum=0.959, 42 actions\n",
      "Episode : 554 rsum=0.961, 40 actions\n",
      "Episode : 555 rsum=0.957, 44 actions\n",
      "Episode : 556 rsum=0.957, 44 actions\n",
      "Episode : 557 rsum=0.959, 42 actions\n",
      "Episode : 558 rsum=0.955, 46 actions\n",
      "Episode : 559 rsum=0.959, 42 actions\n",
      "Episode : 560 rsum=0.954, 47 actions\n",
      "Episode : 561 rsum=0.953, 48 actions\n",
      "Episode : 562 rsum=-1, 1 actions\n",
      "Episode : 563 rsum=0.951, 50 actions\n",
      "Episode : 564 rsum=0.95, 51 actions\n",
      "Episode : 565 rsum=0.953, 48 actions\n",
      "Episode : 566 rsum=0.957, 44 actions\n",
      "Episode : 567 rsum=0.953, 48 actions\n",
      "Episode : 568 rsum=0.958, 43 actions\n",
      "Episode : 569 rsum=0.962, 39 actions\n",
      "Episode : 570 rsum=0.944, 57 actions\n",
      "Episode : 571 rsum=0.952, 49 actions\n",
      "Episode : 572 rsum=-1, 1 actions\n",
      "Episode : 573 rsum=0.957, 44 actions\n",
      "Episode : 574 rsum=0.955, 46 actions\n",
      "Episode : 575 rsum=0.949, 52 actions\n",
      "Episode : 576 rsum=0.956, 45 actions\n",
      "Episode : 577 rsum=0.944, 57 actions\n",
      "Episode : 578 rsum=0.952, 49 actions\n",
      "Episode : 579 rsum=0.951, 50 actions\n",
      "Episode : 580 rsum=0.949, 52 actions\n",
      "Episode : 581 rsum=0.956, 45 actions\n",
      "Episode : 582 rsum=0.959, 42 actions\n",
      "Episode : 583 rsum=0.957, 44 actions\n",
      "Episode : 584 rsum=0.943, 58 actions\n",
      "Episode : 585 rsum=0.955, 46 actions\n",
      "Episode : 586 rsum=0.949, 52 actions\n",
      "Episode : 587 rsum=0.957, 44 actions\n",
      "Episode : 588 rsum=0.953, 48 actions\n",
      "Episode : 589 rsum=0.959, 42 actions\n",
      "Episode : 590 rsum=0.953, 48 actions\n",
      "Episode : 591 rsum=0.94, 61 actions\n",
      "Episode : 592 rsum=0.95, 51 actions\n",
      "Episode : 593 rsum=0.952, 49 actions\n",
      "Episode : 594 rsum=0.959, 42 actions\n",
      "Episode : 595 rsum=0.955, 46 actions\n",
      "Episode : 596 rsum=0.961, 40 actions\n",
      "Episode : 597 rsum=0.956, 45 actions\n",
      "Episode : 598 rsum=0.951, 50 actions\n",
      "Episode : 599 rsum=0.956, 45 actions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 600 rsum=0.956, 45 actions\n",
      "Episode : 601 rsum=0.948, 53 actions\n",
      "Episode : 602 rsum=0.952, 49 actions\n",
      "Episode : 603 rsum=0.953, 48 actions\n",
      "Episode : 604 rsum=0.957, 44 actions\n",
      "Episode : 605 rsum=0.961, 40 actions\n",
      "Episode : 606 rsum=0.955, 46 actions\n",
      "Episode : 607 rsum=0.956, 45 actions\n",
      "Episode : 608 rsum=0.955, 46 actions\n",
      "Episode : 609 rsum=0.955, 46 actions\n",
      "Episode : 610 rsum=-1, 1 actions\n",
      "Episode : 611 rsum=0.944, 57 actions\n",
      "Episode : 612 rsum=0.951, 50 actions\n",
      "Episode : 613 rsum=-1, 1 actions\n",
      "Episode : 614 rsum=0.961, 40 actions\n",
      "Episode : 615 rsum=0.958, 43 actions\n",
      "Episode : 616 rsum=0.958, 43 actions\n",
      "Episode : 617 rsum=0.944, 57 actions\n",
      "Episode : 618 rsum=0.954, 47 actions\n",
      "Episode : 619 rsum=0.949, 52 actions\n",
      "Episode : 620 rsum=0.959, 42 actions\n",
      "Episode : 621 rsum=0.95, 51 actions\n",
      "Episode : 622 rsum=0.95, 51 actions\n",
      "Episode : 623 rsum=0.96, 41 actions\n",
      "Episode : 624 rsum=0.96, 41 actions\n",
      "Episode : 625 rsum=0.957, 44 actions\n",
      "Episode : 626 rsum=0.954, 47 actions\n",
      "Episode : 627 rsum=0.958, 43 actions\n",
      "Episode : 628 rsum=0.952, 49 actions\n",
      "Episode : 629 rsum=0.952, 49 actions\n",
      "Episode : 630 rsum=0.961, 40 actions\n",
      "Episode : 631 rsum=0.945, 56 actions\n",
      "Episode : 632 rsum=0.95, 51 actions\n",
      "Episode : 633 rsum=0.954, 47 actions\n",
      "Episode : 634 rsum=0.957, 44 actions\n",
      "Episode : 635 rsum=0.944, 57 actions\n",
      "Episode : 636 rsum=0.952, 49 actions\n",
      "Episode : 637 rsum=0.95, 51 actions\n",
      "Episode : 638 rsum=0.956, 45 actions\n",
      "Episode : 639 rsum=0.958, 43 actions\n",
      "Episode : 640 rsum=0.956, 45 actions\n",
      "Episode : 641 rsum=0.946, 55 actions\n",
      "Episode : 642 rsum=0.952, 49 actions\n",
      "Episode : 643 rsum=0.946, 55 actions\n",
      "Episode : 644 rsum=0.957, 44 actions\n",
      "Episode : 645 rsum=0.957, 44 actions\n",
      "Episode : 646 rsum=0.951, 50 actions\n",
      "Episode : 647 rsum=0.947, 54 actions\n",
      "Episode : 648 rsum=0.956, 45 actions\n",
      "Episode : 649 rsum=0.951, 50 actions\n",
      "Episode : 650 rsum=0.955, 46 actions\n",
      "Episode : 651 rsum=0.947, 54 actions\n",
      "Episode : 652 rsum=0.959, 42 actions\n",
      "Episode : 653 rsum=0.95, 51 actions\n",
      "Episode : 654 rsum=0.955, 46 actions\n",
      "Episode : 655 rsum=0.958, 43 actions\n",
      "Episode : 656 rsum=0.952, 49 actions\n",
      "Episode : 657 rsum=0.954, 47 actions\n",
      "Episode : 658 rsum=0.957, 44 actions\n",
      "Episode : 659 rsum=0.954, 47 actions\n",
      "Episode : 660 rsum=0.956, 45 actions\n",
      "Episode : 661 rsum=0.939, 62 actions\n",
      "Episode : 662 rsum=0.953, 48 actions\n",
      "Episode : 663 rsum=0.947, 54 actions\n",
      "Episode : 664 rsum=0.949, 52 actions\n",
      "Episode : 665 rsum=0.948, 53 actions\n",
      "Episode : 666 rsum=0.959, 42 actions\n",
      "Episode : 667 rsum=0.955, 46 actions\n",
      "Episode : 668 rsum=0.954, 47 actions\n",
      "Episode : 669 rsum=0.955, 46 actions\n",
      "Episode : 670 rsum=0.958, 43 actions\n",
      "Episode : 671 rsum=0.951, 50 actions\n",
      "Episode : 672 rsum=0.951, 50 actions\n",
      "Episode : 673 rsum=0.956, 45 actions\n",
      "Episode : 674 rsum=0.958, 43 actions\n",
      "Episode : 675 rsum=0.959, 42 actions\n",
      "Episode : 676 rsum=0.954, 47 actions\n",
      "Episode : 677 rsum=0.958, 43 actions\n",
      "Episode : 678 rsum=0.954, 47 actions\n",
      "Episode : 679 rsum=0.96, 41 actions\n",
      "Episode : 680 rsum=0.956, 45 actions\n",
      "Episode : 681 rsum=0.949, 52 actions\n",
      "Episode : 682 rsum=0.949, 52 actions\n",
      "Episode : 683 rsum=0.949, 52 actions\n",
      "Episode : 684 rsum=0.943, 58 actions\n",
      "Episode : 685 rsum=0.941, 60 actions\n",
      "Episode : 686 rsum=0.95, 51 actions\n",
      "Episode : 687 rsum=0.956, 45 actions\n",
      "Episode : 688 rsum=0.958, 43 actions\n",
      "Episode : 689 rsum=0.954, 47 actions\n",
      "Episode : 690 rsum=0.947, 54 actions\n",
      "Episode : 691 rsum=0.944, 57 actions\n",
      "Episode : 692 rsum=0.959, 42 actions\n",
      "Episode : 693 rsum=0.957, 44 actions\n",
      "Episode : 694 rsum=0.953, 48 actions\n",
      "Episode : 695 rsum=0.955, 46 actions\n",
      "Episode : 696 rsum=0.95, 51 actions\n",
      "Episode : 697 rsum=0.958, 43 actions\n",
      "Episode : 698 rsum=0.955, 46 actions\n",
      "Episode : 699 rsum=0.957, 44 actions\n",
      "Episode : 700 rsum=0.952, 49 actions\n",
      "Episode : 701 rsum=0.946, 55 actions\n",
      "Episode : 702 rsum=0.954, 47 actions\n",
      "Episode : 703 rsum=0.957, 44 actions\n",
      "Episode : 704 rsum=-1, 1 actions\n",
      "Episode : 705 rsum=0.957, 44 actions\n",
      "Episode : 706 rsum=0.949, 52 actions\n",
      "Episode : 707 rsum=0.955, 46 actions\n",
      "Episode : 708 rsum=0.955, 46 actions\n",
      "Episode : 709 rsum=0.958, 43 actions\n",
      "Episode : 710 rsum=0.956, 45 actions\n",
      "Episode : 711 rsum=0.958, 43 actions\n",
      "Episode : 712 rsum=0.945, 56 actions\n",
      "Episode : 713 rsum=0.96, 41 actions\n",
      "Episode : 714 rsum=0.948, 53 actions\n",
      "Episode : 715 rsum=-1, 1 actions\n",
      "Episode : 716 rsum=0.952, 49 actions\n",
      "Episode : 717 rsum=0.956, 45 actions\n",
      "Episode : 718 rsum=0.96, 41 actions\n",
      "Episode : 719 rsum=0.951, 50 actions\n",
      "Episode : 720 rsum=0.958, 43 actions\n",
      "Episode : 721 rsum=0.955, 46 actions\n",
      "Episode : 722 rsum=0.961, 40 actions\n",
      "Episode : 723 rsum=-1, 1 actions\n",
      "Episode : 724 rsum=0.955, 46 actions\n",
      "Episode : 725 rsum=-1.001, 2 actions\n",
      "Episode : 726 rsum=0.951, 50 actions\n",
      "Episode : 727 rsum=0.956, 45 actions\n",
      "Episode : 728 rsum=0.95, 51 actions\n",
      "Episode : 729 rsum=0.945, 56 actions\n",
      "Episode : 730 rsum=0.958, 43 actions\n",
      "Episode : 731 rsum=0.956, 45 actions\n",
      "Episode : 732 rsum=0.954, 47 actions\n",
      "Episode : 733 rsum=0.952, 49 actions\n",
      "Episode : 734 rsum=0.955, 46 actions\n",
      "Episode : 735 rsum=0.955, 46 actions\n",
      "Episode : 736 rsum=0.959, 42 actions\n",
      "Episode : 737 rsum=0.949, 52 actions\n",
      "Episode : 738 rsum=0.962, 39 actions\n",
      "Episode : 739 rsum=0.954, 47 actions\n",
      "Episode : 740 rsum=0.954, 47 actions\n",
      "Episode : 741 rsum=0.953, 48 actions\n",
      "Episode : 742 rsum=0.953, 48 actions\n",
      "Episode : 743 rsum=0.947, 54 actions\n",
      "Episode : 744 rsum=0.948, 53 actions\n",
      "Episode : 745 rsum=0.956, 45 actions\n",
      "Episode : 746 rsum=0.959, 42 actions\n",
      "Episode : 747 rsum=0.953, 48 actions\n",
      "Episode : 748 rsum=0.952, 49 actions\n",
      "Episode : 749 rsum=0.952, 49 actions\n",
      "Episode : 750 rsum=0.957, 44 actions\n",
      "Episode : 751 rsum=0.943, 58 actions\n",
      "Episode : 752 rsum=0.95, 51 actions\n",
      "Episode : 753 rsum=0.948, 53 actions\n",
      "Episode : 754 rsum=0.953, 48 actions\n",
      "Episode : 755 rsum=0.96, 41 actions\n",
      "Episode : 756 rsum=0.951, 50 actions\n",
      "Episode : 757 rsum=0.953, 48 actions\n",
      "Episode : 758 rsum=0.953, 48 actions\n",
      "Episode : 759 rsum=0.958, 43 actions\n",
      "Episode : 760 rsum=0.952, 49 actions\n",
      "Episode : 761 rsum=0.963, 38 actions\n",
      "Episode : 762 rsum=0.953, 48 actions\n",
      "Episode : 763 rsum=-1.001, 2 actions\n",
      "Episode : 764 rsum=0.953, 48 actions\n",
      "Episode : 765 rsum=0.954, 47 actions\n",
      "Episode : 766 rsum=0.951, 50 actions\n",
      "Episode : 767 rsum=0.943, 58 actions\n",
      "Episode : 768 rsum=0.952, 49 actions\n",
      "Episode : 769 rsum=0.951, 50 actions\n",
      "Episode : 770 rsum=0.955, 46 actions\n",
      "Episode : 771 rsum=0.954, 47 actions\n",
      "Episode : 772 rsum=0.945, 56 actions\n",
      "Episode : 773 rsum=0.949, 52 actions\n",
      "Episode : 774 rsum=0.95, 51 actions\n",
      "Episode : 775 rsum=-1, 1 actions\n",
      "Episode : 776 rsum=0.951, 50 actions\n",
      "Episode : 777 rsum=0.955, 46 actions\n",
      "Episode : 778 rsum=0.956, 45 actions\n",
      "Episode : 779 rsum=0.955, 46 actions\n",
      "Episode : 780 rsum=0.954, 47 actions\n",
      "Episode : 781 rsum=0.954, 47 actions\n",
      "Episode : 782 rsum=0.961, 40 actions\n",
      "Episode : 783 rsum=0.956, 45 actions\n",
      "Episode : 784 rsum=0.957, 44 actions\n",
      "Episode : 785 rsum=0.951, 50 actions\n",
      "Episode : 786 rsum=0.952, 49 actions\n",
      "Episode : 787 rsum=0.957, 44 actions\n",
      "Episode : 788 rsum=0.956, 45 actions\n",
      "Episode : 789 rsum=0.951, 50 actions\n",
      "Episode : 790 rsum=0.957, 44 actions\n",
      "Episode : 791 rsum=0.96, 41 actions\n",
      "Episode : 792 rsum=0.951, 50 actions\n",
      "Episode : 793 rsum=0.959, 42 actions\n",
      "Episode : 794 rsum=0.95, 51 actions\n",
      "Episode : 795 rsum=0.956, 45 actions\n",
      "Episode : 796 rsum=0.953, 48 actions\n",
      "Episode : 797 rsum=0.956, 45 actions\n",
      "Episode : 798 rsum=0.957, 44 actions\n",
      "Episode : 799 rsum=0.949, 52 actions\n",
      "Episode : 800 rsum=0.956, 45 actions\n",
      "Episode : 801 rsum=0.954, 47 actions\n",
      "Episode : 802 rsum=0.952, 49 actions\n",
      "Episode : 803 rsum=0.95, 51 actions\n",
      "Episode : 804 rsum=0.962, 39 actions\n",
      "Episode : 805 rsum=0.953, 48 actions\n",
      "Episode : 806 rsum=0.9349999999999999, 66 actions\n",
      "Episode : 807 rsum=0.949, 52 actions\n",
      "Episode : 808 rsum=0.945, 56 actions\n",
      "Episode : 809 rsum=0.959, 42 actions\n",
      "Episode : 810 rsum=0.954, 47 actions\n",
      "Episode : 811 rsum=0.956, 45 actions\n",
      "Episode : 812 rsum=0.96, 41 actions\n",
      "Episode : 813 rsum=0.964, 37 actions\n",
      "Episode : 814 rsum=0.949, 52 actions\n",
      "Episode : 815 rsum=-1, 1 actions\n",
      "Episode : 816 rsum=0.958, 43 actions\n",
      "Episode : 817 rsum=0.953, 48 actions\n",
      "Episode : 818 rsum=-1.001, 2 actions\n",
      "Episode : 819 rsum=0.947, 54 actions\n",
      "Episode : 820 rsum=-1, 1 actions\n",
      "Episode : 821 rsum=0.954, 47 actions\n",
      "Episode : 822 rsum=0.95, 51 actions\n",
      "Episode : 823 rsum=0.952, 49 actions\n",
      "Episode : 824 rsum=0.949, 52 actions\n",
      "Episode : 825 rsum=0.955, 46 actions\n",
      "Episode : 826 rsum=0.951, 50 actions\n",
      "Episode : 827 rsum=0.946, 55 actions\n",
      "Episode : 828 rsum=0.954, 47 actions\n",
      "Episode : 829 rsum=0.946, 55 actions\n",
      "Episode : 830 rsum=0.96, 41 actions\n",
      "Episode : 831 rsum=0.945, 56 actions\n",
      "Episode : 832 rsum=0.953, 48 actions\n",
      "Episode : 833 rsum=0.955, 46 actions\n",
      "Episode : 834 rsum=0.947, 54 actions\n",
      "Episode : 835 rsum=0.96, 41 actions\n",
      "Episode : 836 rsum=0.95, 51 actions\n",
      "Episode : 837 rsum=0.96, 41 actions\n",
      "Episode : 838 rsum=0.961, 40 actions\n",
      "Episode : 839 rsum=0.953, 48 actions\n",
      "Episode : 840 rsum=0.949, 52 actions\n",
      "Episode : 841 rsum=0.95, 51 actions\n",
      "Episode : 842 rsum=0.952, 49 actions\n",
      "Episode : 843 rsum=0.955, 46 actions\n",
      "Episode : 844 rsum=0.946, 55 actions\n",
      "Episode : 845 rsum=0.958, 43 actions\n",
      "Episode : 846 rsum=0.96, 41 actions\n",
      "Episode : 847 rsum=0.956, 45 actions\n",
      "Episode : 848 rsum=0.95, 51 actions\n",
      "Episode : 849 rsum=0.954, 47 actions\n",
      "Episode : 850 rsum=0.95, 51 actions\n",
      "Episode : 851 rsum=0.944, 57 actions\n",
      "Episode : 852 rsum=0.954, 47 actions\n",
      "Episode : 853 rsum=0.954, 47 actions\n",
      "Episode : 854 rsum=0.955, 46 actions\n",
      "Episode : 855 rsum=0.955, 46 actions\n",
      "Episode : 856 rsum=0.946, 55 actions\n",
      "Episode : 857 rsum=0.958, 43 actions\n",
      "Episode : 858 rsum=0.956, 45 actions\n",
      "Episode : 859 rsum=0.956, 45 actions\n",
      "Episode : 860 rsum=0.949, 52 actions\n",
      "Episode : 861 rsum=0.96, 41 actions\n",
      "Episode : 862 rsum=0.947, 54 actions\n",
      "Episode : 863 rsum=0.961, 40 actions\n",
      "Episode : 864 rsum=0.952, 49 actions\n",
      "Episode : 865 rsum=0.958, 43 actions\n",
      "Episode : 866 rsum=0.951, 50 actions\n",
      "Episode : 867 rsum=0.942, 59 actions\n",
      "Episode : 868 rsum=0.958, 43 actions\n",
      "Episode : 869 rsum=0.95, 51 actions\n",
      "Episode : 870 rsum=0.958, 43 actions\n",
      "Episode : 871 rsum=0.954, 47 actions\n",
      "Episode : 872 rsum=0.949, 52 actions\n",
      "Episode : 873 rsum=0.96, 41 actions\n",
      "Episode : 874 rsum=0.956, 45 actions\n",
      "Episode : 875 rsum=0.955, 46 actions\n",
      "Episode : 876 rsum=0.955, 46 actions\n",
      "Episode : 877 rsum=0.955, 46 actions\n",
      "Episode : 878 rsum=0.942, 59 actions\n",
      "Episode : 879 rsum=0.957, 44 actions\n",
      "Episode : 880 rsum=0.962, 39 actions\n",
      "Episode : 881 rsum=0.956, 45 actions\n",
      "Episode : 882 rsum=0.948, 53 actions\n",
      "Episode : 883 rsum=0.96, 41 actions\n",
      "Episode : 884 rsum=0.947, 54 actions\n",
      "Episode : 885 rsum=0.949, 52 actions\n",
      "Episode : 886 rsum=0.948, 53 actions\n",
      "Episode : 887 rsum=0.952, 49 actions\n",
      "Episode : 888 rsum=0.955, 46 actions\n",
      "Episode : 889 rsum=0.956, 45 actions\n",
      "Episode : 890 rsum=0.952, 49 actions\n",
      "Episode : 891 rsum=0.958, 43 actions\n",
      "Episode : 892 rsum=0.945, 56 actions\n",
      "Episode : 893 rsum=0.951, 50 actions\n",
      "Episode : 894 rsum=0.957, 44 actions\n",
      "Episode : 895 rsum=0.955, 46 actions\n",
      "Episode : 896 rsum=0.956, 45 actions\n",
      "Episode : 897 rsum=0.959, 42 actions\n",
      "Episode : 898 rsum=0.948, 53 actions\n",
      "Episode : 899 rsum=0.943, 58 actions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 900 rsum=-1.002, 3 actions\n",
      "Episode : 901 rsum=0.958, 43 actions\n",
      "Episode : 902 rsum=0.938, 63 actions\n",
      "Episode : 903 rsum=0.953, 48 actions\n",
      "Episode : 904 rsum=0.958, 43 actions\n",
      "Episode : 905 rsum=0.954, 47 actions\n",
      "Episode : 906 rsum=0.957, 44 actions\n",
      "Episode : 907 rsum=0.962, 39 actions\n",
      "Episode : 908 rsum=0.964, 37 actions\n",
      "Episode : 909 rsum=0.955, 46 actions\n",
      "Episode : 910 rsum=0.959, 42 actions\n",
      "Episode : 911 rsum=0.949, 52 actions\n",
      "Episode : 912 rsum=0.949, 52 actions\n",
      "Episode : 913 rsum=0.949, 52 actions\n",
      "Episode : 914 rsum=0.951, 50 actions\n",
      "Episode : 915 rsum=0.95, 51 actions\n",
      "Episode : 916 rsum=0.952, 49 actions\n",
      "Episode : 917 rsum=0.954, 47 actions\n",
      "Episode : 918 rsum=0.955, 46 actions\n",
      "Episode : 919 rsum=0.948, 53 actions\n",
      "Episode : 920 rsum=0.958, 43 actions\n",
      "Episode : 921 rsum=0.952, 49 actions\n",
      "Episode : 922 rsum=0.951, 50 actions\n",
      "Episode : 923 rsum=0.942, 59 actions\n",
      "Episode : 924 rsum=0.956, 45 actions\n",
      "Episode : 925 rsum=0.947, 54 actions\n",
      "Episode : 926 rsum=0.958, 43 actions\n",
      "Episode : 927 rsum=0.96, 41 actions\n",
      "Episode : 928 rsum=0.958, 43 actions\n",
      "Episode : 929 rsum=0.962, 39 actions\n",
      "Episode : 930 rsum=0.955, 46 actions\n",
      "Episode : 931 rsum=0.951, 50 actions\n",
      "Episode : 932 rsum=0.956, 45 actions\n",
      "Episode : 933 rsum=0.957, 44 actions\n",
      "Episode : 934 rsum=0.954, 47 actions\n",
      "Episode : 935 rsum=0.95, 51 actions\n",
      "Episode : 936 rsum=0.956, 45 actions\n",
      "Episode : 937 rsum=0.944, 57 actions\n",
      "Episode : 938 rsum=0.951, 50 actions\n",
      "Episode : 939 rsum=0.953, 48 actions\n",
      "Episode : 940 rsum=0.949, 52 actions\n",
      "Episode : 941 rsum=0.959, 42 actions\n",
      "Episode : 942 rsum=0.955, 46 actions\n",
      "Episode : 943 rsum=-1, 1 actions\n",
      "Episode : 944 rsum=0.957, 44 actions\n",
      "Episode : 945 rsum=0.951, 50 actions\n",
      "Episode : 946 rsum=0.956, 45 actions\n",
      "Episode : 947 rsum=0.944, 57 actions\n",
      "Episode : 948 rsum=0.951, 50 actions\n",
      "Episode : 949 rsum=0.961, 40 actions\n",
      "Episode : 950 rsum=0.956, 45 actions\n",
      "Episode : 951 rsum=0.96, 41 actions\n",
      "Episode : 952 rsum=0.949, 52 actions\n",
      "Episode : 953 rsum=0.948, 53 actions\n",
      "Episode : 954 rsum=0.95, 51 actions\n",
      "Episode : 955 rsum=0.955, 46 actions\n",
      "Episode : 956 rsum=0.95, 51 actions\n",
      "Episode : 957 rsum=0.951, 50 actions\n",
      "Episode : 958 rsum=-1.001, 2 actions\n",
      "Episode : 959 rsum=0.953, 48 actions\n",
      "Episode : 960 rsum=0.954, 47 actions\n",
      "Episode : 961 rsum=0.956, 45 actions\n",
      "Episode : 962 rsum=0.956, 45 actions\n",
      "Episode : 963 rsum=0.952, 49 actions\n",
      "Episode : 964 rsum=-1.001, 2 actions\n",
      "Episode : 965 rsum=0.944, 57 actions\n",
      "Episode : 966 rsum=0.958, 43 actions\n",
      "Episode : 967 rsum=0.961, 40 actions\n",
      "Episode : 968 rsum=0.951, 50 actions\n",
      "Episode : 969 rsum=0.946, 55 actions\n",
      "Episode : 970 rsum=0.959, 42 actions\n",
      "Episode : 971 rsum=0.96, 41 actions\n",
      "Episode : 972 rsum=0.948, 53 actions\n",
      "Episode : 973 rsum=0.956, 45 actions\n",
      "Episode : 974 rsum=0.948, 53 actions\n",
      "Episode : 975 rsum=0.957, 44 actions\n",
      "Episode : 976 rsum=0.96, 41 actions\n",
      "Episode : 977 rsum=-1, 1 actions\n",
      "Episode : 978 rsum=0.952, 49 actions\n",
      "Episode : 979 rsum=0.955, 46 actions\n",
      "Episode : 980 rsum=0.952, 49 actions\n",
      "Episode : 981 rsum=0.962, 39 actions\n",
      "Episode : 982 rsum=0.949, 52 actions\n",
      "Episode : 983 rsum=0.954, 47 actions\n",
      "Episode : 984 rsum=0.945, 56 actions\n",
      "Episode : 985 rsum=0.952, 49 actions\n",
      "Episode : 986 rsum=0.954, 47 actions\n",
      "Episode : 987 rsum=0.954, 47 actions\n",
      "Episode : 988 rsum=0.954, 47 actions\n",
      "Episode : 989 rsum=0.951, 50 actions\n",
      "Episode : 990 rsum=0.952, 49 actions\n",
      "Episode : 991 rsum=0.952, 49 actions\n",
      "Episode : 992 rsum=0.949, 52 actions\n",
      "Episode : 993 rsum=0.954, 47 actions\n",
      "Episode : 994 rsum=0.957, 44 actions\n",
      "Episode : 995 rsum=0.953, 48 actions\n",
      "Episode : 996 rsum=0.954, 47 actions\n",
      "Episode : 997 rsum=0.952, 49 actions\n",
      "Episode : 998 rsum=0.954, 47 actions\n",
      "Episode : 999 rsum=0.963, 38 actions\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# log file plusieurs scenarios\n",
    "outdir = 'gridworld-v0/random-agent-results'\n",
    "envm = wrappers.Monitor(env, directory=outdir, force=True , video_callable=False )\n",
    "env.setPlan(\"gridworldPlans/plan10.txt\", {0: -0.001, 3: 1, 4: 1, 5: -1, 6: -1})\n",
    "env.seed()  # randomness init\n",
    "\n",
    "statedic , _ = env.getMDP()\n",
    "################## AGENT ################## \n",
    "agent = Epsilon_Policy_Agent( env, Method=\"Value_iteration\" )\n",
    "###########################################\n",
    "\n",
    "episode_count = 1000\n",
    "reward = 0\n",
    "done = False\n",
    "rsum = 0\n",
    "FPS = 0.0001\n",
    "for i in range(episode_count):\n",
    "    obs = envm.reset()\n",
    "    env.verbose = (i % 100 == 0 and i > 0)  # render 1 episode / 100\n",
    "    if env.verbose:\n",
    "        env.render(FPS)\n",
    "    j = 0\n",
    "    rsum = 0\n",
    "    while True:\n",
    "        # convert state string to its encoding number \n",
    "        encoded_state = statedic[str(obs.tolist())]\n",
    "        action = agent.act( encoded_state , reward , done )\n",
    "        obs, reward, done, _ = envm.step(action)\n",
    "        rsum += reward\n",
    "        j += 1\n",
    "        if env.verbose:\n",
    "            env.render(FPS)\n",
    "        if done:\n",
    "            print(\"Episode : \" + str(i) + \" rsum=\" + str(rsum) + \", \" + str(j) + \" actions\")\n",
    "            break\n",
    "\n",
    "print(\"done\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best values for **empty cases reward** in several arena of GridWorld using epsilon greedy approach with value iteration algorithm :\n",
    "- Plan0 (-0.1)\n",
    "- Plan1 (-0.1)\n",
    "- Plan2 (-0.01)\n",
    "- Plan3 (-0.001)\n",
    "- Plan4 (-0.1)\n",
    "- Plan5 (-0.001)\n",
    "- Plan6 (-0.001) \n",
    "- Plan7 (-0.01)\n",
    "- Plan8 (-0.01)\n",
    "- Plan9 : statedic , _ = env.getMDP() RecursionError: maximum recursion depth exceeded while getting the repr of     an object\n",
    "- Plan10 (-0.001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.ImageFolder(root=\"./plots/\",\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_imgs = torch.Tensor()\n",
    "for i in range(len(dataset)) :\n",
    "    tensor_imgs = torch.cat([ tensor_imgs , dataset[i][0].view(1,3,480,640)] , 0  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 3, 480, 640])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "make_grid() got an unexpected keyword argument 'nrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-80f2bb203f2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Images\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_imgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: make_grid() got an unexpected keyword argument 'nrows'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x1296 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(tensor_imgs, padding=2, nrow=3, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
